l=[1,2,3]
ll=reversed(l)
print type(ll)  # <type 'listreverseiterator'>
----------
>>> x = 1234.56789
>>> # Two decimal places of accuracy
>>> format(x, '0.2f')
'1234.57'
>>> # Right justified in 10 chars, one-digit accuracy
>>> format(x, '>10.1f')
'    1234.6'
>>> # Left justified
>>> format(x, '<10.1f')
'1234.6    '
>>> # Centered
>>> format(x, '^10.1f')
'  1234.6  '
>>> # Inclusion of thousands separator
>>> format(x, ',')
'1,234.56789'
>>> format(x, ',.1f')
'1,234.6'
format优点:
    1.format方式比％操作符更为灵活，使用format方式时，参数的顺序与格式化的顺序不必完全相同
        weather= [('Monday', 'rain'), ('Tuesday', 'sunny'), ('Wednesday', 'sunny'), ('Thursday', 'rain'), ('Friday', 'cloudy')]
        formatter = "Weather of {0[0]} is {0[1]}".format
        for item in map(formatter, weather):
            print item
    2.format可以方便地作为参数传递
----------
>>> x = 1234
>>> bin(x)
'0b10011010010'
>>> oct(x)
'0o2322'
>>> hex(x)
'0x4d2'
>>> # 如果你不想输出 0b , 0o 或者 0x 的前缀的话，可以使用 format() 函数
>>> format(x, 'b')
'10011010010'
>>> format(x, 'o')
'2322'
>>> format(x, 'x')
'4d2'
----------
如果你想要漂亮的将文件中的json文档打印出来，你可以用以下这种方式：
    cat file.json | python -m json.tools
----------
>>> 1/2
0
>>> 1.0/2
0.5
>>> from __future__ import division
>>> 1/2
0.5
----------
In [5]: [1,2]==[2,1]
Out[5]: False
----------
Python File flush() 方法: fileObject.flush()
flush() 方法是用来刷新缓冲区的，即将缓冲区中的数据立刻写入文件，同时清空缓冲区，一般情况下，文件关闭后会自动刷新缓冲区，但有时你需要在关闭前刷新它，这时就可以使用 flush() 方法。
----------
traceback知道在哪个文件哪个函数哪一行报的错:

import traceback
try:
    1/0
except Exception, e:
    traceback.print_exc()
输出结果
Traceback (most recent call last):
    File "test_traceback.py", line 3, in <module>
        1/0
ZeroDivisionError: integer division or modulo by zero
这样非常直观有利于调试。
----------
rsa load_pkcs1_openssl_pem: BEGIN PUBLIC KEY
rsa load_pkcs1: BEGIN RSA PUBLIC KEY
----------
def hex_to_char(one):
    # '0x61' -> 'a'
    # '0x1' -> '\x01'
    # '0x01' -> '\x01'
    return chr(int(one, 16))

def char_to_hex(one):
    # 'a' -> '0x61'
    # '\x01' -> '0x1'
    return hex(ord(one))

hexlify = binascii.hexlify  # '\x61' -> '61', '\x01' -> '01'

chr() 用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应的字符。
语法:
    chr(i)
        参数 i 可以是10进制也可以是16进制的形式的数字。
>>>In [19]: chr(0xA0)
>>>Out[19]: '\xa0'

0x is used for literal numbers. "\x" is used inside strings to represent a character
>>> 0x41
65
>>> "\x41"
'A'
>>> "\x01"  # a non printable character
'\x01'
----------
python --help
-m mod(不带.py后缀): 将库中的python模块用作脚本去运行。
----------
print list(set(a).intersection(set(b)))  # 两列表交集
print list(set(a).union(set(b)))  # 两列表并集
print list(set(b).difference(set(a)))  # 两列表差集, b中有而a中没有的, 非常高效！
----------
**kwargs.pop('x', None)
>>> d={}
>>> d.setdefault('a','a')
'a'
>>> d
{'a': 'a'}
>>> d.setdefault('a','b')
'a'
>>> d
{'a': 'a'}

dict.setdefault(key, default=None)
如果key在字典中，返回对应的值。如果不在字典中，则插入key及设置的默认值default，并返回default，default默认值为None。
----------
sorted()不会改变原来的list，而是会返回一个新的已经排序好的list。
list.sort()方法仅仅被list所定义，sorted()可用于任何一个可迭代对象。
----------
Ignore some testcases:
    @unittest.skip('skip is upper.')
----------
无限小: float('-Inf')
----------
和index()不同的是find()在找不到substring时不会抛出异常，而是会返回-1，因此不会影响程序的执行
----------
装饰器其实就是一个闭包，把一个函数当做参数然后返回一个替代版函数。
----------
静态字段只在内存中保存一份，普通字段在每个对象中都要保存一份。方法方法包括：普通方法、静态方法和类方法，三种方法在内存中都归属于类，区别在于调用方式不同。
----------
think of the Logger logging level as a global restriction on which messages are "interesting" for a given logger and its handlers. The messages that are considered by the logger afterwards get sent to the handlers, which perform their own filtering and logging process.

.. code:: python
    import logging
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    fromatter = logging.Formatter('%(asctime)s-%(message)s')
    handler = logging.StreamHandler()
    handler.setLevel(logging.ERROR)
    handler.setFormatter(fromatter)
    logger.addHandler(handler)
    try:
        open('/path/to/does/not/exist', 'rb')
    except (SystemExit, KeyboardInterrupt):
        raise
    except Exception, e:
        logger.error('Failed to open file', exc_info=True)

logger按info过滤，之后传给它的handlers，handler有自己的level规则，按error再过滤传来的log。
----------
ord('E')以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值。

转16进制:
In [38]: ord('E')
Out[38]: 69
In [41]: hex(69)
Out[41]: '0x45'

\x45 vs 0x45:
In [48]: 0x45
Out[48]: 69
In [49]: '\x45'
Out[49]: 'E'
In [60]: ord('\x45')
Out[60]: 69

chr(69)用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应的字符。

In [58]: int('0x45',16)
Out[58]: 69

In [59]: int('45',16)
Out[59]: 69

In [60]: int('\x45',16)
Out[60]: 14

In [57]: chr(69)
Out[57]: 'E'

 1 def str_to_hex(s):
 2     return ' '.join([hex(ord(c)).replace('0x', '') for c in s])
 3 
 4 def hex_to_str(s):
 5     return ''.join([chr(i) for i in [int(b, 16) for b in s.split(' ')]])
 6     
 7 def str_to_bin(s):
 8     return ' '.join([bin(ord(c)).replace('0b', '') for c in s])
 9     
10 def bin_to_str(s):
11     return ''.join([chr(i) for i in [int(b, 2) for b in s.split(' ')]])
----------
python进程池apply与apply_async的区别:
apply方法是阻塞的。
意思就是等待当前子进程执行完毕后，在执行下一个进程。
apply_async 是异步非阻塞的。
意思就是：不用等待当前进程执行完毕，随时根据系统调度来进行进程切换。
----------
进程虽然不像线程那样共享内存的数据，而是每个进程有单独的内存，但多进程也是共享文件系统的，即硬盘系统；当多进程同时写入文件操作时，可能造成数据的破坏，因此进程也存在同步锁。
进程锁可以保证文件系统的安全，但是它使得并行变成了串行，效率下降了，也可能造成死锁问题，一般避免用锁机制。
----------
python的stdout是有缓冲区的，给你个例子你就知道了

import time
import sys
 
for i in range(5):
    print i,
    #sys.stdout.flush()
    time.sleep(1)
    
这个程序本意是每隔一秒输出一个数字，但是如果把这句话sys.stdout.flush()注释的话，你就只能等到程序执行完毕，屏幕上会一次性输出0，1，2，3，4。
如果你加上sys.stdout.flush()，刷新stdout，这样就能每隔一秒输出一个数字了。
----------
python两个有趣属性
__all__可用于模块导入时限制，如：
    from module import *
    此时被导入模块若定义了__all__属性，则只有all内指定的属性、方法、类可被导入~
    若没定义，则模块内的所有将被导入。

__slots__用于限定类属性，如：
    class A(object):
        __slots__ = ['var']

    此时外部调用时，如：
    a = A()
    a.var = 4    #不会报错
    a.other = 4  #此时则会抛出异常AttributeError
----------
一个ascii码就是一个字节， 因为ascll码的二进制范围是00000000到11111111， 十进制范围是0到255。

1字节=8位
一个16进制为0xf，一个16进制数为四个二进制数,0x0为0000,0xf为1111，即1个16进制数为4位; 1个8进制数为3位。

UE软件打开bmp图像，如42 4D 38 04 04 00 00 00 00 00 36 04 00 00，每两个16进制数隔开，用意是：因为1个16进制数为4位，两个就是8位，即1个字节，所以这里是14字节，是位图文件头，以字节为单位，容易计数。

内存的储存单元是字节。
----------
我们将服务端程序分为了web服务器和应用程序服务器。

web服务器是用于处理HTML文件，让客户可以通过浏览器进行访问。主流的有apache,IIS,nginx,lghttpd等。
应用服务器处理业务逻辑，比如使用python的django,flask写成的程序

通常来自客户端浏览器的请求被web服务器截获，如果是静态请求，则nginx会自己做处理，如果是动态请求，则会抛给后端应用服务器来处理。于是如何在web服务器与应用服务器之间进行通信成了主要问题，这就引出了三种处理的接口：CGI，FastCGI，WSGI。
----------
要理解select.select模块其实主要就是要理解它的参数，以及其三个返回值。
select()方法接收并监控3个通信列表，第一个是所有的输入的data，就是指外部发过来的数据，第2个是监控和接收所有要发出去的data(outgoing data)，第3个监控错误信息。
select() returns three new lists, containing subsets of the contents of the lists passed in. All of the sockets in the readable list have incoming data buffered and available to be read. All of the sockets in the writable list have free space in their buffer and can be written to. The sockets returned in exceptional have had an error (the actual definition of “exceptional condition” depends on the platform).
----------
In [10]: '\xe6\x97\xb6\xe9\x97\xb4'.decode('utf-8')
Out[10]: u'\u65f6\u95f4'
----------
python中字符串自带的split方法一次只能使用一个字符对字符串进行分割，但是python的正则模块则可以实现多个字符分割
import re
re.split('[_#|]','this_is#a|test')
返回的是一个列表（list），输出结果如下：
['this', 'is', 'a', 'test']
----------
显示分数
from fractions import Fraction

In [25]: print Fraction(11, 35)
11/35

In [27]: print Fraction(1.5)
3/2
----------
静态方法主要是用来存放逻辑性的代码，逻辑上属于类，但是和类本身没有关系，也就是说在静态方法中，不会涉及到类中的属性和方法的操作。静态方法是个独立的、单纯的函数，它仅仅托管于某个类的名称空间中，便于使用和维护。
----------
The threading library defines the following objects for synchronizing threads. synchronize threads so that only one thread can make modifications to shared data at any given time.
• Lock
    Always try to follow this prototype
    # Example critical section
    x = 0
    x_lock = threading.Lock()
    x_lock.acquire()
    try:
        statements using x
    finally:
        x_lock.release()

    # Python 2.6/3.0 has an improved mechanism for dealing with locks and critical sections.
    with x_lock:
        statements using x
• RLock
• Semaphore
    • Resource control.   You can limit the number of threads performing certain operations.  For example, performing database queries, making network connections, etc.
        m = threading.Semaphore(n)  # only n threads can be executing the function at once (if there are more, they will have to wait)
    • Signaling. Semaphores can be used to send "signals" between threads.  For example, having one thread wake up another thread.
        Using a semaphore to signal
        done = threading.Semaphore(0)
        thread1: done.release()
        thread1: done.acquire()
        Here, acquire() and release() occur in different threads and in a different order
        Often used with producer-consumer problems
    Unlike locks, acquire()/release() can be called in any order and by any thread.
    Semaphore 在内部管理着一个计数器。调用 acquire() 会使这个计数器 -1，release() 则是+1.
    计数器的值永远不会小于 0，当计数器到 0 时，再调用 acquire() 就会阻塞，直到其他线程来调用release()
    Semaphore 支持上下文管理协议
• BoundedSemaphore
    BoundedSemaphore正好和Semaphore相反：一个工厂函数，返回一个新的有界信号量对象。有界信号量会确保他的值不会超过初始值；
    如果超出则会抛出ValueError异常。初始值默认为1。
• Event
    事件处理的机制：全局定义了一个“Flag”，线程通过wait()方法进入等待状态，直到另一个线程调用该Event的set()方法将Flag设置为True时，
    该Event会通知所有wait的线程恢复运行。
    This can be used to have one or more  threads wait for something to occur.
    Setting an event will unblock all waiting threads simultaneously (if any)
• Condition
    A combination of locking/signaling.
----------
There are three major setup.py commands we will use:
::
    bdist_egg: This creates an egg file. This is what is necessary so someone can use easy_install your_project.
    bdist_wininst: This will create an .exe that will install your project on a windows machine.
    sdist: This create a raw source distribution which someone can download and run python setup.py directly.
----------
traceback.print_exc()跟traceback.format_exc()有什么区别呢？
::
    format_exc()返回字符串，print_exc()则直接给打印出来。
        即traceback.print_exc()与print traceback.format_exc()效果是一样的。
    print_exc()还可以接受file参数直接写入到一个文件。比如
        traceback.print_exc(file=open('tb.txt','w+'))
----------
.. code:: python
    import sys
    import logging
    logging.basicConfig(level=logging.DEBUG)
    logger = logging.getLogger(__name__)

    def hook(exc_type, exc_value, exc_traceback):
        logger.debug('%s-%s-%s' % (exc_type, exc_value, exc_traceback.tb_lineno))

    sys.excepthook = hook

    def test():
    raise Exception('test')


    if __name__ == '__main__':
        test()

    >>> DEBUG:__main__:<type 'exceptions.Exception'>-test-19
----------
Use isort to automate import sorting using the guidelines below
::
    $ pip install isort
    $ isort -rc .
----------
注释代码:
    NOTE: Description of how the code works (when it isn't self evident).
    XXX: Warning about possible pitfalls, can be used as NOTE:XXX:.
    HACK: Not very well written or malformed code to circumvent a problem/bug. Should be used as HACK:FIXME:.
    FIXME: This works, sort of, but it could be done better. (usually code written in a hurry that needs rewriting).
    BUG: There is a problem here.
    TODO: No problem, but addtional code needs to be written, usually when you are skipping something.
----------
mock.patch('xxx') error: TypeError: Need a valid target to patch. You supplied: 'xxx'
    The patch decorator requires the target to be a full dotted path: mock.patch('x.xx.xxx')
mock 抛出一个异常:
    @patch("aa.classA.getnum")
    def test_self_function(self, mock_getnum):
        mock_getnum.side_effect = IOError()

@mock.patch('my_module.os.path')
@mock.patch('my_module.os')
def test(self, mock_os, mock_path):
    pass
----------
Request如何传递对象:

data = {
            'handle_data': [
                {
                    'row_key': self.alert_record[0],
                    'handle_plan_status': 'handled',
                    'handle_plan_data': {
                        'remarks': 'remarks',
                    },
                    'alert_status': 'alerting',
                },
            ]
}
response = self.client_patch(
    self.base_url,
    data=json.dumps(data),
    content_type="application/json",
)
----------
eval 在做计算前并不知道需要转化的内容是不是合法的python数据类型。只是在调用函数的时候去计算。如果被计算的内容不是合法的python类型就会抛出异常。
ast.literal则会判断需要计算的内容计算后是不是合法的python类型，如果是则进行运算，否则就不进行运算。
推荐使用ast.literal_eval
>>> import ast
>>> ast.literal_eval("545.2222")
545.2222
>>> ast.literal_eval("31")
31
----------
每个logger都有一个日志级别。写入logger的每条消息都是一个日志记录。每个日志记录也具有一个日志级别，它表示对应的消息的严重性。
当一条消息传递给logger时，消息的日志级别将与logger的日志级别进行比较。如果消息的日志级别大于等于logger的日志级别，该消息将会往下继续处理。如果小于，该消息将被忽略。
Handler决定如何处理logger中的每条消息。它描述了一个详细的日志行为，例如将消息写到屏幕上、写到文件中或者写到网络socket。如果日志记录的日志级别小于handler的级别，handler将忽略该消息。
一个filter被用来对从logger传递给handler的日志记录进行额外的控制。默认情况下，任何满足日志级别要求的日志消息都将被处理。然而，通过安装一个filter，你可以对日志处理添加额外的条件。例如，你可以安装一个filter，只允许处理来自特定源的ERROR消息。
Filters可以被用来修改将要发送的日志记录的优先级。例如，如果日志记录满足特定的条件，你可以编写一个filter将日志记录从ERROR降为WARNING。
Filters可以安装在logger上或者handler上。多个filter可以串联起来，实现多层filter行为。
习惯上，logger的名称通常使用__name__，即包含该logger的Python模块的名字。点号分隔的logger名字定义一个层级。a logger被认为是 a.b logger的父级，a.b logger 被认为是 a.b.c logger 的父级。
层级为何如此重要？因为，loggers可以传播它们的logging调用给它们的父级。通过这种方式，你可以在logger树的顶部定义一系列的handlers，并捕获在logger子树中的所有logging调用。在a命名空间中，定义的handler将捕获 a.b 和 a.b.c logger 上的所有日志消息。
这种传播行为，可以基于每个logger进行控制。如果，你不想让某个logger传播消息给它的父级，你可以关闭这个行为。

'filters': {
    'special': {
        '()': 'project.logging.SpecialFilter',
        'foo': 'bar',
    },
    'require_debug_true': {
        '()': 'django.utils.log.RequireDebugTrue',
    },
},
如果filter在构造时，要求额外的参数，可以在filter的配置字典中用额外的键提供。在这个例子中，在实例化SpecialFilter时，foo参数被赋予'bar'值。
----------
打开浏览器网页: os.system(u"open /Applications/Google\ Chrome.app http://www.google.com")
----------
def application(environ, start_response):
    start_response('200 OK', [('Content-Type', 'text/html')])
    return '<h1>Hello, web!</h1>'
无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。HTTP请求的所有输入信息都可以通过environ获得，HTTP响应的输出都可以通过start_response()加上函数返回值作为Body。
----------
::
    __new__方法接受的参数虽然也是和__init__一样，但__init__是在类实例创建之后调用，而 __new__方法正是创建这个类实例的方法。
.. code:: python
    def __new__(cls, name, age):
        print '__new__ called.'
        return super(Person, cls).__new__(cls, name, age)
    def __init__(self, name, age):
        print '__init__ called.'
        self.name = name
        self.age = age
----------
.. code:: python
    class Fib(object):
        def __init__(self):
            self.a, self.b = 0, 1 # 初始化两个计数器a，b

        def __iter__(self):
            return self # 实例本身就是迭代对象，故返回自己

        def next(self):
            self.a, self.b = self.b, self.a + self.b # 计算下一个值
            if self.a > 100000: # 退出循环的条件
                raise StopIteration();
            return self.a # 返回下一个值
----------
对于container类型（列表是典型的container），可以直接用于for循环进行遍历。而将列表转化成迭代器Iterator进行遍历，效果似乎一样。

为什么两种方法都可以呢？Python到底是怎样遍历一个container的呢？前面提到Python的迭代器iterator实现两种方法分别是__iter__和next，Python正是通过调用这两种方法来实现遍历的。首先，当Python在执行for循环时，会先调用container的__iter__方法来获得container的迭代器iterator，其实就是将container转化成迭代器iterator。然后它会重复调用迭代器iterator的next()方法，直到迭代器iterator抛出StopIteration异常。一旦这个异常抛出，for循环就结束了。
----------
from argparse import RawTextHelpFormatter
parser = argparse.ArgumentParser(formatter_class=RawTextHelpFormatter)
parser.add_argument() 在help使用 \n 可以换行

The dest paramter told argparse to use a variable named in dest, not in '--name'
----------
Python跳过第一行读取文件内容
from itertools import islice
f = open('test.txt')
for i in islice(f, 1, None):
    print i
islice(iterable, [start,] stop [, step])
----------
In [12]: {}.fromkeys(['a', 'b', 'c'], 'xx')
Out[12]: {'a': 'xx', 'b': 'xx', 'c': 'xx'}
----------
for 循环还有一个 else 从句，这个 else 从句会在循环正常结束时执行。这意味着，循环没有遇到任何 break。
有个常见的构造是跑一个循环，并查找一个元素。如果这个元素被找到了，我们使用 break 来中断这个循环。有两个场景会让循环停下来。
* 第一个是当一个元素被找到， break 被触发。
* 第二个场景是循环结束。
现在我们也许想知道其中哪一个，才是导致循环完成的原因。一个方法是先设置一个标记，然后在循环结束时打上标记。另一个是使用 else 从句。
这就是 for/else 循环的基本结构：
.. code:: python
    for item in container:
        if search_something(item):
            # Found it!
            process(item)
            break
    else:
        # Didn't find anything..
        not_found_in_container()
----------
PEP8 换行

**Yes**:

# Aligned with opening delimiter.
foo = long_function_name(var_one, var_two,
                         var_three, var_four)

# Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.
def long_function_name(
        var_one, var_two, var_three,
        var_four):
    print(var_one)

# Hanging indents should add a level.
foo = long_function_name(
    var_one, var_two,
    var_three, var_four)

# How to break a line of chained methods in Python?

history = instance.history.only('prefix_request_id') \
    .filter(operation_type='prefix') \
    .last()

**No**:

# Arguments on first line forbidden when not using vertical alignment.
foo = long_function_name(var_one, var_two,
    var_three, var_four)

# Further indentation required as indentation is not distinguishable.
def long_function_name(
    var_one, var_two, var_three,
    var_four):
    print(var_one)
----------
代码的解释器指令集:
compile(source, filename, mode[, flags[, dont_inherit]])
    source - a normal string, a byte string, or an AST object
    filename - file from which the code was read. If it wasn't read from a file, you can give a name yourself
    mode - Either exec or eval or single.
        eval - accepts only a single expression.
        exec - It can take a code block that has Python statements, class and functions and so on.
        single - if it consists of a single interactive statement
import dis
code=compile('print "a"', '', 'exec')
print dis.disassemble(code)
----------
上下左右箭头乱码: pip install readline
----------
In [4]: filter(None,[1,2,None,3,None])
Out[4]: [1, 2, 3]
----------
import os, psutil
查看内存信息: psutil.Process(os.getpid()).memory_info()
返回 pmem(rss, vms, pfaults, pageins), rss: Resident Set Size, 实际使用物理内存, 单位字节数
----------
.. code:: python
    try:
        1/0
    except ZeroDivisionError as e:
        raise
print:
::
    Traceback (most recent call last):
      File "qtest.py", line 7, in <module>
        1/0
    ZeroDivisionError: integer division or modulo by zero

# 不知道哪里报错:
.. code:: python
    try:
        1/0
    except ZeroDivisionError as e:
        raise e
print:
::
    Traceback (most recent call last):
      File "qtest.py", line 9, in <module>
        raise e
    ZeroDivisionError: integer division or modulo by zero
----------
Multiple if's means your code would go and check all the if conditions, where as in case of elif, if one if condition satisfies it would not check other conditions..
----------
默认情况下，我们自己定义的类的实例总被认为是真的，除非这个类对 __bool__ 或者 __len__ 函数有自己的实现。
.. code:: python
    class A(object):
        def __len__(self):
            return 0
    a = A()
    print bool(a)  # False

    class A(object):
        pass
    a = A()
    print bool(a)  # True
----------
Python 标准库用 C 实现了丰富的序列类型，列举如下。
容器序列
    list、tuple 和 collections.deque 这些序列能存放不同类型的数据。
扁平序列
    str、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。
容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是引用。换句话说，扁平序列其实是一段连续的内存空间。
----------
inspect模块用于收集python对象的信息，可以获取类或函数的参数的信息，源码，解析堆栈，对对象进行类型检查等等
----------
显示毫秒 & %F %X
In [2]: print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'))
2019-04-18 11:35:22.137031

In [5]: print(datetime.datetime.now().strftime('%F %X'))
2019-04-18 11:35:44
----------
If an object defines both __get__() and __set__(), it is considered a data descriptor.
Descriptors that only define __get__() are called non-data descriptors (they are typically used for methods but other uses are possible).

If an instance’s dictionary has an entry with the same name as a data descriptor, the data descriptor takes precedence.
If an instance’s dictionary has an entry with the same name as a non-data descriptor, the dictionary entry takes precedence.

To make a read-only data descriptor, define both __get__() and __set__() with the __set__() raising an AttributeError when called
----------
fabric带参数用法:
def hello(name="world"):
    print("Hello %s!" % name)

$ fab hello:name=Jeff
Hello Jeff!
----------
convert timedela to seconds:
    >>> import datetime
    >>> datetime.timedelta(seconds=24*60*60).total_seconds()
    86400.0
----------
numpy set difference
In [80]: aa
Out[80]: array([1, 2, 3, 4, 5, 6, 7, 8])

In [81]: bb
Out[81]: array([2, 3, 4, 5])

In [79]: np.setdiff1d(aa,bb)
Out[79]: array([1, 6, 7, 8])
----------
更好的函数命名:
.. code:: python
    # Wrong Way
    def get_user_info(id):
        db = get_db_connection()
        user = execute_query_for_user(id)
        return user
    # Right way
    def get_user_by(user_id):
        db = get_db_connection()
        user = execute_user_query(user_id)
        return user
----------
Here is a restructured text doc example (the official Python documents recommend this):
.. code:: python
    def call_weather_api(url, location):
        """Get the weather of specific location.

        Calling weather api to check for weather by using weather api
        and location. Make sure you provide city name only, country and
        county names won't be accepted and will throw exception if not
        found the city name.

        :param url:  URL of the api to get weather.
        :type url: str
        :param location:  Location of the city to get the weather.
        :type location: str
        :return: Give the weather information of given location.
        :rtype: str
        """
        pass
----------
Prefer to Have Minimum Code Under try. Whenever you handle an exception in your code, try to keep the code in
a try block at a minimum.
----------
在一些场景中我们经常需要自动生成一些临时文件，当然用简单的open函数，来创建一个隐藏文件可以实现。不过tempfile这个模块把一些有的没的功能全部都封装完毕。我们直接使用即可。
.. code:: python

    from tempfile import TemporaryFile

    temp = TemporaryFile()
    print temp  # <open file '<fdopen>', mode 'w+b' at 0x110be7420>
    print temp.name  # <fdopen>
    '''
    TemporaryFile类的构造方法，其返回的还是一个文件对象。但这个文件对象特殊的地方在于
    1. 对应的文件没有文件名，对除了本程序之外的程序不可见
    2. 在被关闭的同时被删除
    所以上面的两句打印语句，输出分别是一个文件对象，以及一个<fdopen>（并不是文件名）
    '''
    # 向临时文件中写入内容
    temp.write('hello\nworld')

    # ...一些操作之后需要读取临时文件的内容了
    temp.seek(0)     # 从头读取，和一般文件对象不同，seek方法的执行不能少
    print temp.read()

    temp.close()    # 关闭文件的同时删除文件
----------
There are two things that you as a programmer can do before shipping code off (ship off: 遣送) to production to make sure that you are shipping quality code.
    * Logging
    * Unit test
----------
Class Structure:
::
    I prefer a class structure in this order:
    1. Class variables
    2. __init__
    3. Built-in Python special methods (__call__,
    __repr__, etc.)
    4. Class methods
    5. Static methods
    6. Properties
    7. Instance methods
    8. Private methods
.. code:: python

    class Employee(Person):
        POSITIONS = ("Superwiser", "Manager", "CEO", "Founder")
        def __init__(self, name, id, department):
            self.name = name
            self.id = id
            self.department = department
            self.age = None
            self._age_last_calculated = None
            self._recalculated_age()
        def __str__(self):
            return ("Name: " + self.name + "\nDepartment: "
                   + self.department)
        @classmethod
        def no_position_allowed(cls, position):
            return [t for t in cls.POSITIONS if t != position]
        @staticmethod
        def c_positions(position):
            return [t for t in cls.TITLES if t in position]
        @property
        def id_with_name(self):
            return self.id, self.name
        def age(self):
            if (datetime.date.today() > self._age_last_recalculated):
                self.__recalculated_age()
            return self.age
        def _recalculated_age(self):
            today = datetime.date.today()
            age = today.year - self.birthday.year
            if today < datetime.date(
               today.year, self.birthday.month,
               self.birthday.year):
                age -= 1
            self.age = age
            self._age_last_recalculated = today
----------
There are two places you can consider using @property in a class: in complex code hidden behind an attribute and in the validation of the set attribute.
----------
Abstract Class the Right Way
.. code:: python
    from abc import ABCMeta, abstractmethod
    class Fruit(metaclass=ABCMeta):
        @abstractmethod
        def taste(self):
            pass
        @abstractmethod
        def originated(self):
            pass
    class Apple:
        def originated(self):
            return "Central Asia"
----------
A class method gives you the flexibility to create alternative constructors besides using the __init__ method, so it’s one of the easiest ways to create a factory pattern in Python.
.. code:: python

    class User:
        def __init__(self, first_name, last_name):
            self.first_name = first_name
            self.last_name = last_name

        @classmethod
        def using_string(cls, names_str):
            first, second = map(str, names_str.split(""))
            student = cls(first, second)
            return Student

        @classmethod
        def using_json(cls, obj_json):
            # parsing json object...
            return Student

        @classmethod
        def using_file_obj(cls, file_obj):
            # parsing file object...
            return Student

        >>> data = User.using_string("Larry Page")
        >>> data = User.using_json(json_obj)
        >>> data = User.using_file_obj(file_obj)
----------
# __new__ for Assigning a Value:
.. code:: python

    class UserAbstract(metaclass=ABCMeta):
        """Abstract base class template, implementing factory pattern using __new__() initializer."""

        def __new__(cls, *args, **kwargs):
        """Creates an object instance and sets a base property."""
            obj = object.__new__(cls)
            obj.base_property = "Adding Property for each subclass"
            return obj

    class User(UserAbstract):
    """Implement UserAbstract class and add its own variable."""

        def __init__(self):
            self.name = "Larry"

    >>> user = User()
    >>> user.name
    Larry
    >>> user.base_property
    Adding Property for each subclass


# __new__ for Validating the Provided Value:
.. code:: python

    from abc import abstractmethod, ABCMeta

    class UserAbstract(metaclass=ABCMeta):
    """Abstract base class template, implementing factory pattern using __new__() initializer."""

        def __new__(cls, *args, **kwargs):
        """Creates an object instance and sets a base property."""
            obj = object.__new__(cls)
            given_data = args[0]
            # Validating the data here
            if not isinstance(given_data, str):
                raise ValueError(f"Please provide string: {given_
                data}")
            return obj

    class User(UserAbstract):
    """Implement UserAbstract class and add its own variable."""

        def __init__(self, name):
            self.name = Name

    >>> user = User(10)
    ValueError: Please provide string: 10

----------
Prevent Creating an Object Directly:
.. code:: python

    class NoClassInstance:
    """Create the user object."""
        def __call__(self, *args, **kwargs):
            raise TypeError("Can't instantiate directly""")

    class User(metaclass=NoClassInstance):
        @staticmethod
        def print_name(name):
        """print name of the provided value."""
            print(f"Name: {name}")

    >>> user = User()
    TypeError: Can't instantiate directly
    >>> User.print_name("Larry Page")
    Name: Larry Page

API Design Using __call__
.. code:: python

    class Calculation:
        """
        A wrapper around the different calculation algorithms that
        allows to perform different action on two numbers.
        """
        def __init__(self, operation):
            self.operation = operation

        def __call__(self, first_number, second_number):
            if isinstance(first_number, int) and isinstance(second_
            number, int):
                return self.operation()
            raise ValueError("Provide numbers")

    def add(self, first, second):
        return first + second

    def multiply(self, first, second):
        return first * second

    >>> add = Calculation(add)
    >>> print(add(5, 4))
    9
    >>> multiply = Calculation(multiply)
    >>> print(multiply(5, 4))
    20

Implement Instance Caching Using __call__
.. code:: python

    class Memo(type):

        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.__cache = {}

        def __call__(self, id, *args, **kwargs):
            if id not in self.__cache:
                self.__cache[id] = super().__call__(id, *args, **kwargs)
            else:
                print("Existing Instance")
            return self.__cache[id]

    class Foo(Memo):
        def __init__(self, id, *args, **kwargs):
            self._id = id

    def test():
        first = Foo("first")
        second = Foo("first")
        print(id(first) == id(second))

    >>> test()
    True

----------
Class Decorators for Maintaining State and Validating Parameters:
.. code:: python

    import functools
    class Count:
        def __init__(self, func):
            functools.update_wrapper(self, func)
            self.func = func
            self.num = 1

        def __call__(self, *args, **kwargs):
            self.num += 1
            print "Number of times called: {}".format(self.num)
            return self.func(*args, **kwargs)

    @Count
    def counting_hello():
        print("Hello")

    >>> counting_hello()
    Number of times called: 2
    >>> counting_hello()
    Number of times called: 3

.. code:: python

    import functools
    class ValidateParameters:
        def __init__(self, func):
            functools.update(self, func)
            self.func = func

        def __call__(self, *args, **kwargs):
            if any([isinstance(item, int) for item in parameters]):
                raise TypeError("Parameter shouldn't be int!!")
            else:
                return self.func(*parameters)

    @ValidateParameters
    def add_numbers(*list_string):
        return "".join(list_string)

    #  returns anb
    >>> print(concate("a", "n", "b"))
    # raises Error.
    >>> print(concate("a", 1, "c"))

----------
1、_name 不能用于’from module import *’ 以单下划线开头的表示的是protected类型的变量。即保护类型只能允许其本身与子类进行访问。

2、__name 双下划线的表示的是私有类型的变量。只能是允许这个类本身进行访问了。连也是子类也不可以的。
----------
memoryview:
    1. 内存查看对象(Memory view)的构造函数，返回内存查看对象。
    2. 所谓内存查看对象，是指对支持缓冲区协议的数据进行包装，在不需要复制对象基础上允许Python代码访问。
    3. Python内置对象中支持缓冲区协议的对象有bytes和bytearray。
----------
任何对象，只要正确实现了上下文管理，就可以用于with语句。实现上下文管理是通过__enter__和__exit__实现的，也可以通过@contextmanager和closing函数实现。
.. code:: python
    class closing(object):
        """Context to automatically close something at the end of a block.
        Code like this:
            with closing(<module>.open(<arguments>)) as f:
                <block>
        is equivalent to this:
            f = <module>.open(<arguments>)
            try:
                <block>
            finally:
                f.close()
        """
        def __init__(self, thing):
            self.thing = thing
        def __enter__(self):
            return self.thing
        def __exit__(self, *exc_info):
            self.thing.close()

这个contextlib.closing()会帮它加上__enter__()和__exit__()，使其满足with的条件。

.. code:: python
    from contextlib import contextmanager

    @contextmanager
    def tag(name):
        print("<%s>" % name)
        yield
        print("</%s>" % name)

    with tag("h1"):
        print 'hello world!'

yield前半段用来表示__enter__()
yield后半段用来表示__exit__()
----------
 from happybase import Connection
    c = Connection(...)
    t = c.table('my_table')
    count = 0
    for _ in t.scan(filter='FirstKeyOnlyFilter() AND KeyOnlyFilter()'):
        count += 1

    print count
----------
scan(row_start=None, row_stop=None, row_prefix=None, columns=None, filter=None, timestamp=None, include_timestamp=False, batch_size=1000, scan_batching=None, limit=None, sorted_columns=False)

row_start：起始行，默认None，即第一行，可传入行号指定从哪一行开始
row_stop：结束行，默认None，即最后一行，可传入行号指定到哪一行结束(不获取此行数据)
row_prefix：行号前缀，默认为None，即不指定前缀扫描，可传入前缀来扫描符合此前缀的行
columns：列，默认为None，即获取所有列，可传入一个list或tuple来指定获取列
filter：过滤字符串
timestamp：时间戳。默认为None，即返回最大的那个时间戳的数据。可传入一个时间戳来获取小于此时间戳的最大时间戳的版本数据
include_timestamp：是否返回时间戳数据，默认为False
batch_size：用于检索结果的批量大小
scan_batching：服务端扫描批处理
limit：数量
sorted_columns：是否返回排序的列(根据行名称排序)
reverse：是否执行反向扫描
----------
itertools.dropwhile(predicate, iterable) 根据真值表舍弃第一个不满足条件前面的值
>>> x = itertools.dropwhile(lambda e: e < 5, range(10))
>>> print(list(x))
[5, 6, 7, 8, 9]
----------
If you use Queue.Queue together with multiprocessing. A Queue.Queue will not be shared between processes.
If the Queue.Queue is declared before the processes then each process will receive a copy of it which is then independent of every other process.

Items placed in the Queue.Queue by the parent before starting the children will be available to each child.
Items placed in the Queue.Queue by the parent after starting the child will only be available to the parent.

Queue.Queue is made for data interchange (思想、信息等的交换，互换) between different threads inside the same process (using the threading module).
The multiprocessing queues are for data interchange between different Python processes. While the API looks similar (it's designed to be that way), the underlying mechanisms are fundamentally different.

multiprocessing queues exchange data by pickling (serializing) objects and sending them through pipes.
Queue.Queue uses a data structure that is shared between threads and locks/mutexes for correct behaviour.
----------
Gunicorn (WSGI协议的一个容器，和uWSGI一样的功能)
----------
一个对象的弱引用并不足以使得对象存在。当一个对象仅仅剩下弱引用的时候，python的垃圾回收机制会回收销毁这些对象，收回内存。弱引用的一个主要用途就是来实现缓存或者大对象的映射。
----------
In [2]: os.pardir
Out[2]: '..'
----------
yield from:
.. codeing:: python
    # 考虑我们有多个 generator 并想把 generator 组合起来，如：

    def odds(n):
        for i in range(n):
            if i % 2 == 1:
                yield i

    def evens(n):
        for i in range(n):
            if i % 2 == 0:
                yield i

    def odd_even(n):
        for x in odds(n):
            yield x
        for x in evens(n):
            yield x

    for x in odd_even(6):
        print(x)  # => 1, 3, 5, 0, 2, 4

    # for x in generator(): yield x 这种写法不太方便，因此 PEP 380 引入了 yield from 语法，上面的例子可以改成：
    def odd_even(n):
        yield from odds(n)
        yield from evens(n)
----------
协程可以在执行期间暂停，这样就可以等待外部的处理（例如IO）完成之后，从之前暂停的地方恢复执行。
生成器是迭代器，会生成传给 yield 关键字的表达式的值。
yield表示协程在此暂停，并且将执行权交给其他协程。因为协程可以将值与控制权一起传递给另一个协程，所以“yield一个值”就表示将值传给下一个执行的协程。
事件循环: 在Asyncio模块中，**每一个进程都有一个事件循环**。
什么是事件循环
    在计算系统中，可以产生事件的实体叫做事件源，能处理事件的实体叫做事件处理者。此外，还有一些第三方实体叫做事件循环。它的作用是管理所有的事件，在整个程序运行过程中不断循环执行，追踪事件发生的顺序将它们放到队列中，当主线程空闲的时候，调用相应的事件处理者处理事件。最后，我们可以通过下面的伪代码来理解事件循环:
    while (1) {
        events = getEvents();
        for (e in events)
            processEvent(e);
    }
所有的事件都在 while 循环中捕捉，然后经过事件处理者处理。事件处理的部分是系统唯一活跃的部分，当一个事件处理完成，流程继续处理下一个事件。
    loop = get_event_loop(): 得到当前上下文的事件循环。
    loop.call_later(time_delay, callback, argument): 延后 time_delay 秒再执行 callback 方法。
    loop.call_soon(callback, argument): 尽可能快调用 callback, call_soon() 函数结束，主线程回到事件循环之后就会马上调用 callback 。
    loop.time(): 以float类型返回当前时间循环的内部时间。
    asyncio.set_event_loop(): 为当前上下文设置事件循环。
    asyncio.new_event_loop(): 根据此策略创建一个新的时间循环并返回。
    loop.run_forever(): 在调用 stop() 之前将一直运行。

asyncio 是用来编写并发代码的库，使用 async/await 语法。
async/await实际上只是 @asyncio.coroutine和yield from 的语法糖：
    把 @asyncio.coroutine 替换为 async
    把 yield from 替换为 await  # yield from iterable 等于 for item in iterable: yield item 的缩写版

    @asyncio.coroutine用来标记基于生成器的协程的装饰器。基于生成器的协程是使用 yield from 语句创建的 Python 生成器，可以等待 Future 和其他协程。
    此装饰器使得旧式的基于生成器的协程能与 async/await 代码相兼容:
    @asyncio.coroutine
    def old_style_coroutine():
        yield from asyncio.sleep(1)

    async def main():
        await old_style_coroutine()

    此装饰器 已弃用 并计划觉得 Python 3.10 中移除。
    此装饰器不应该被用于 async def 协程。

coro 缩写 Coroutines
Coroutine 是协程。
可等待 对象有三种主要类型: 协程, 任务 和 Future.
Future 是一种特殊的 低层级 可等待对象，表示一个异步操作的 最终结果。
Future 包裹了协程，为协程添加了回调模式，可以指定结果成功和失败时的回调函数。
当一个 Future 对象 被等待，这意味着协程将保持等待直到该 Future 对象在其他地方操作完毕。

Task 对协程对象在事件循环的执行负责。如果一个协程在等待一个 Future 对象，Task 对象会挂起该协程的执行并等待该 Future 对象完成。当该 Future 对象 完成，被打包的协程将恢复执行。当一个任务在等待future执行的期间，事件循环会运行一个新的任务。

Asyncio是用来处理事件循环中的异步进程和并发任务执行的。它还提供了 asyncio.Task() 类，可以在任务中使用协程。**Task的作用是，在同一事件循环中,运行某一个任务的同时可以并发地运行多个任务**。当协程被包在任务中，它会自动将任务和事件循环连接起来，当事件循环启动的时候，任务自动运行。这样就提供了一个可以自动驱动协程的机制。

事件循环使用协同日程调度: 一个事件循环每次运行一个 Task 对象。而一个 Task 对象会等待一个 Future 对象完成，该事件循环会运行其他 Task、回调或执行 IO 操作。

协程的行为有点像函数调用，它和函数调用的不同在于，对于函数调用来说，假如A函数调用B函数，则必须等待B函数执行完毕之后程序运行流程才会重新走回A，但是对于协程来说，如果在协程A中切到协程B，协程B可以选择某个点重新回到A的执行流，同时允许在某个时刻重新从A回到B之前回到A的那个点，这在函数中是不可能实现的。因为函数只能一走到底。

因为子例程只返回一次，要返回多个值就要通过集合的形式。这在有些语言，如Forth里很方便；而其他语言，如C，只允许单一的返回值，所以就需要引用一个集合。相反地，因为协程可以返回多次，返回多个值只需要在后继的协程调用中返回附加的值即可。在后继调用中返回附加值的协程常被称为产生器。
----------
线程同步机制中，下面的对象可以使用 with 语法：
    Lock
    RLock
    Condition
    Semaphore
----------
queue.task_done 主要是给queue.join用的，每次get后需要调用task_done，直到所有任务都task_done。join才取消阻塞。
queue.join:
    Blocks until all items in the Queue have been gotten and processed.
    The count of unfinished tasks goes up whenever an item is added to the
    queue. The count goes down whenever a consumer thread calls **task_done()**
    to indicate the item was retrieved and all work on it is complete.

.. code:: python
    class consumer(Thread):
        def __init__(self, queue):
            Thread.__init__(self)
            self.queue = queue

        def run(self):
            while True:
                item = self.queue.get()
                print('Consumer notify : %d popped from queue by %s' % (item, self.name))
                self.queue.task_done()
----------
Multiprocessing库有两个Communication Channel可以交换对象：队列(queue)和管道（pipe）。
----------
read 读取整个文件，输出为字符串，readlines 读取整个文件，输出为列表。
----------
.. coding:: python
    # Python program to demonstrate ternary operator
    a, b = 10, 20

    # Use tuple for selecting an item
    print( (b, a) [a < b] )

    # Use Dictionary for selecting an item
    print({True: a, False: b} [a < b])

    # lamda is more efficient than above two methods
    # because in lambda we are assure that only one
    # expression will be evaluated unlike in tuple and Dictionary
    print((lambda: b, lambda: a)[a < b]())

    >>> Output:
    10
    10
    10
----------
python中getpass的作用是输入密码不可见:
.. coding:: python
    import getpass
    password = getpass.getpass('Input password: ')
    print password
----------
判断一个对象的属性是否存在，若不存在就添加该属性:
    getattr(t, "age", setattr(t, "age", "18"))
----------
python2 urllib模块urlretrieve方法: 将远程数据下载到本地
urllib.urlretrieve(url, filename=None, reporthook=None, data=None, context=None)
    url：外部或者本地url。
    filename：保存到本地的路径，如果未指定，urllib会生成一个临时文件来保存数据。
    reporthook：回调函数，当连接上服务器、以及相应的数据块传输完毕的时候会触发该回调。我们可以利用这个回调函数来显示当前的下载进度。
    data：指post到服务器的数据。该方法返回一个包含两个元素的元组(filename, headers)，filename表示保存到本地的路径，header表示服务器的响应头。
.. coding:: python
    import os
    import urllib
    def cbk(a, b, c):
    '''回调函数
    @a:已经下载的数据块
    @b:数据块的大小
    @c:远程文件的大小
    '''
        per = 100.0 * float(a * b) / float(c)
        if per > 100:
            per = 100
        print("a", a)
        print("b", b)
        print("c", c)
        print('{:.2f}%'.format(per))

    url='https://www.cnblogs.com'
    dir=os.path.abspath('.')
    work_path=os.path.join(dir, 'cnblogs.html')
    urllib.urlretrieve(url, work_path, cbk)
----------
Python标准库提供了易用的上下文管理器工具模块contextlib，它是通过生成器实现的，我们不需要创建类以及__enter__和__exit__这两个特殊的方法:
.. coding:: python
    from contextlib import contextmanager

    @contextmanager
    def make_open_context(filename, mode):
        fp = open(filename, mode)
        try:
            yield fp
        finally:
            fp.close()

    with make_open_context('/tmp/a.txt', 'a') as file_obj:
        file_obj.write("hello world")

在上文中，yield关键词把上下文分割成两部分：yield之前就是__init__中的代码块；yield之后其实就是__exit__中的代码块，yield生成的值会绑定到with语句as子句中的变量，例如在上面的例子中，yield生成的值是文件句柄对象fp，在下面的with语句中，会将fp和file_obj绑定到一起，也就是说file_obj此时就是一个文件句柄对象，那么它就可以操作文件了，因此就可以调用file_obj.write("hello world")，另外要注意的是**如果yield没有生成值，那么在with语句中就不需要写as子句了**:
.. coding:: python
    from contextlib import contextmanager

    @contextmanager
    def book_mark():
        print('《', end="")
        yield
        print('》', end="")

    with book_mark():
        print('且将生活一饮而尽', end="")
    >>> 《且将生活一饮而尽》
----------
dir()函数会自动寻找一个对象的所有属性，包括__dict__中的属性。
__dict__是dir()的子集，dir()包含__dict__中的属性。
----------
Celery Flower:
    Flower does not process tasks. You must run both, then Flower can be used as a monitoring tool.
    Run celery:
        celery -A tasks worker --loglevel=info
    Open another shell and run flower:
        celery -A tasks flower --loglevel=info
----------
Testing the installation
Verify that the packages are installed correctly:
.. coding:: python
    (envname) $ python -c 'import happybase'  # **python -c**
----------
python traceback捕获并打印异常
.. coding:: python
    try:
        1/0
    except Exception, e:
        print e
输出结果: integer division or modulo by zero, 只知道是报了错，却不知道在哪个文件哪个函数哪一行报的错。

使用traceback:
    try:
        1/0
    except Exception, e:
        traceback.print_exc()
输出结果:
Traceback (most recent call last):
    File "test_traceback.py", line 3, in <module>
        1/0
ZeroDivisionError: integer division or modulo by zero

format_exc()返回字符串，print_exc()则直接给打印出来。即traceback.print_exc()与print traceback.format_exc()效果是一样的。
print_exc()还可以接受file参数直接写入到一个文件。比如 traceback.print_exc(file=open('tb.txt','w+')) 写入到tb.txt文件去。
----------
ord是unicode ordinal的缩写，chr是character的缩写，ord和chr是互相对应转换的，但是由于chr局限于ascii,长度只有256，于是又多了个unichr。
.. coding:: python
    >>> c = u'康'
    >>> c
        u'\u5eb7'
    >>> ord(c)
        24747
    >>> chr(24247)
        ValueError: chr() arg not in range(256)
    >>> unichr(24247)
        u'\u5eb7'
----------
1. 同一个引用
.. coding:: python
    >>> a = range(3)
    >>> a
        [0, 1, 2]
    >>> b = a
    >>> b
        [0, 1, 2]
    >>> b[0]='kzc'
    >>> b
        ['kzc', 1, 2]
    >>> a
        ['kzc', 1, 2]
可以看到，改变b时，a也跟着变了。这是因为赋值的是引用。其实a和b指向同一个对象。
可以用b = a[:]或者b = a+[]解决。
上面的解决方法是浅拷贝的，如果列表a比较复杂，比如列表里面嵌套列表，就需要深拷贝才能彻底解决了。
即利用copy模块，b = copy.deepcopy(a)。
顺带，字典也是引用。

2. 遍历的时候改变值
    >>> arr = ['a','b','c','kzc']
    >>> for i in arr:
    ...:    if i!='kzc':
    ...:        arr.remove(i)
    ...:
    >>> arr
        ['b', 'kzc']

为什么结果会是这个呢，我可是要把不等于'kzc'的元素删了的。这是因为遍历的跟删除的是同一个引用，同一个对象。
一开始，遍历到第一个元素'a','a'不满足被删掉，arr列表就变成了['b','c','kzc']了，然后i继续往下遍历到第二个元素，注意，这时候arr列表被改变了，
第二个元素成了'c'了，于是'b'就漏掉了。

3. 由于存到redis数据库中的都是字符串，有时候取出来的时候忘记转成整型，造成损失。有一次操作玩家的数值的时候，本来是要加32*3即96的，结果成了'32'*3即'323232'了。
----------
逻辑运算符短路逻辑:
    1. 从左至右运算，若 or 的左侧逻辑值为 True ，则短路 or 后所有的表达式（不管是 and 还是 or），直接输出 or 左侧表达式 。
    2. 从左至右运算，若 and 的左侧逻辑值为 False ，则短路其后所有 and 表达式，直到有 or 出现，输出 and 左侧表达式到 or 的左侧，参与接下来的逻辑运算。
    3. r 的左侧为 False ，或者 and 的左侧为 True 则不能使用短路逻辑。

三元运算操作符: bool ? a : b ，若 bool 为真则 a ，否则为 b 。
----------
带 __slots__ 属性的类定义不会存在__dict__ 了（除非你在 __slots__ 中增加 __dict__ 元素）。
----------
In [5]: data=np.array([i for i in range(10)])

In [6]: np.array_split(data, 3)
Out[6]: [array([0, 1, 2, 3]), array([4, 5, 6]), array([7, 8, 9])]
----------
if io_bound:
    if io_very_slow:
        print("Use Asyncio")
    else:
       print("Use Threads")
else:
    print("Multi Processing")

CPU Bound => Multi Processing
I/O Bound, Fast I/O, Limited Number of Connections => Multi Threading
I/O Bound, Slow I/O, Many connections => Asyncio
----------
* Use a def for named expressions:
.. coding:: python
    Yes:
        def f(x): return 2*x
    No:
        f = lambda x: 2*x

* Insert a break statement into the loop
    If the for loop iterates to completion without being prematurely interrupted by a break or return statement, then Python executes the else clause of the loop. If the else clause should not always execute at the end of a loop clause, then the code should add a break statement within the loop block:
.. coding:: python
    def contains_magic_number(list, magic_number):
        for i in list:
            if i == magic_number:
                print("This list contains the magic number.")
                # added break statement here
                break
        else:
            print("This list does NOT contain the magic number.")

    contains_magic_number(range(10), 5)
    # This list contains the magic number.

* A contextmanager class is any class that implements the __enter__ and __exit__ methods, __exit__ must accept 3 arguments: type, value, traceback

* __init__ is automatically called when memory is allocated for a new object.

* Use a sentinel value to denote an empty list or dictionary, When the function receives the sentinel value, it knows that it is supposed to return a new list or dict.
.. coding:: python
    def append(number, number_list=[]):
        number_list.append(number)
        print(number_list)
        return number_list

    append(5) # expecting: [5], actual: [5]
    append(7) # expecting: [7], actual: [5, 7]
    append(2) # expecting: [2], actual: [5, 7, 2]

    # the keyword None is the sentinel value representing empty list
    def append(number, number_list=None):
        if number_list is None:
            number_list = []
        number_list.append(number)
        print(number_list)
        return number_list

    append(5) # expecting: [5], actual: [5]
    append(7) # expecting: [7], actual: [7]
    append(2) # expecting: [2], actual: [2]

* Use setdefault() to initialize a dictionary:
.. coding:: python
    dictionary = {}
    if "a" not in dictionary:
        dictionary["a"] = []
    dictionary["a"].append("item")

    dictionary = {}
    dictionary.setdefault("a", []).append("item")
    # When setdefault() is called, it will check if the key already exists. If it does exist, then setdefault() does nothing. If the key does not exist, then setdefault() creates it and sets it to the value specified in the second argument.

* The Python community uses an EAFP (easier to ask for forgiveness than permission) coding style.
.. coding:: python
    import os
    # violates EAFP coding style
    if os.path.exists("file.txt"):
        os.unlink("file.txt")  # os.unlink()方法用于删除文件,如果文件是一个目录则返回一个错误。

    import os
    try:
        os.unlink("file.txt")
    # raised when file does not exist
    except OSError:
        pass

* Compare values to None using the pattern if cond is None.

* Use named tuples to return multiple values

* Use zip() to iterate through a pair of lists

* Use a set or dictionary instead of a list to check if key is contained or not. Python can attempt to directly access the target number in the set, rather than iterate through every item in the list and compare every item to the target number.
.. coding:: python
    l = [1, 2, 3, 4]
    # iterates over three elements in the list
    if 3 in l:
        print("The number 3 is in the list.")
    else:
        print("The number 3 is NOT in the list.")

    s = set([1, 2, 3, 4])
    if 3 in s:
        print("The number 3 is in the list.")
    else:
        print("The number 3 is NOT in the list.")
----------
**WSGI** allowed developers to separate choice of a Web framework from choice of a Web server. Now you can actually mix and match Web servers and Web frameworks and choose a pairing that suits your needs. You can run Django, Flask, or Pyramid, for example, with Gunicorn or Nginx/uWSGI or Waitress.
**WSGI Server 流程**:
    First, the server starts and loads an ‘application’ callable provided by your Web framework/application
    Then, the server reads a request
    Then, the server parses it
    Then, it builds an ‘environ’ dictionary using the request data
    Then, it calls the ‘application’ callable with the ‘environ’ dictionary and a ‘start_response’ callable as parameters and gets back a response body.
    Then, the server constructs an HTTP response using the data returned by the call to the ‘application’ object and the status and response headers set by the ‘start_response’ callable.
    And finally, the server transmits the HTTP response back to the client
----------
os._exit(n)
    退出进程，并且返回退出状态n，在退出的时候不会执行清理工作，直接退出。
    注意：正常的退出应该使用sys.exit(n)，而_exit()函数一般只用在fork之后的子进程中调用以退出。

os.wait()
    pid, status = os.wait()
    进程一旦调用了wait，就立即阻塞自己，由wait自动分析是否当前进程的某个子进程已经退出，如果让它找到了这样一个已经变成僵尸的子进程，wait就会收集这个子进程的信息，并把它彻底销毁后返回；如果没有找到这样一个子进程，wait就会一直阻塞在这里，等待任何一个子进程结束。

os.waitpid(pid, options)
    os.wait 遇到任何一个子进程结束就返回，如果同时多个子进程结束，依然会导致僵尸进程出现。
    本质上讲，系统调用waitpid和wait的作用是完全相同的，但waitpid多出了两个可由用户控制的参数pid和options，从而为我们编程提供了另一种更灵活的方式。
        pid>0时，只等待进程ID等于pid的子进程，不管其它已经有多少子进程运行结束退出了，只要指定的子进程还没有结束,waitpid就会一直等下去。
        pid=-1时，等待任何一个子进程退出，没有任何限制，此时waitpid和wait的作用一模一样。
        pid=0时，等待同一个进程组中的任何子进程，如果子进程已经加入了别的进程组，waitpid不会对它做任何理睬。
        pid<-1时，等待一个指定进程组中的任何子进程，这个进程组的ID等于pid的绝对值。
    options 提供了一些额外的选项来控制waitpid
        如果使用了WNOHANG参数调用waitpid，即使没有子进程结束，它也会立即返回，不会像wait那样永远等下去。如果设置了 WNOHANG 且没有子进程退出的话，pid, status = os.wait() pid = 0。
----------
signal包的核心是使用signal.signal()函数来预设(register)信号处理函数，如下所示：
    singnal.signal(signalnum, handler)  signalnum为某个信号，handler为该信号的处理函数。
        当handler为signal.SIG_IGN时，信号被无视(ignore)。
        当handler为singal.SIG_DFL，进程采取默认操作(default)。
        当handler为一个函数名时，进程采取函数中定义的操作。该函数必须接受两个参数，分别是信号量signum，当前程序运行堆栈frame，这两个参数Python解释器会自动传入，因此我们不必显示传入。
    signal.pause()
        使程序阻塞，直到程序接收到某个信号量。如果没有这句话，可以在程序中变更为
            while True:
                pass
        效果一样
    signal.alarm(n)
        隔n秒后发出一个SIGALRM信号
        若注册了ALRM信号的处理函数，则相关处理器会被调用。当time为0时，取消注册ALRM信号处理函数。

.. coding:: python
    import signal
    import time

    def handler(signum, frame):
        if signum == signal.SIGALRM:
            print('时间到了')
        elif signum == signal.SIGINT:
            print("CTRL + C 无效")

    signal.alarm(5)  # 触发SIGALRM信号
    signal.signal(signal.SIGINT, handler)
    signal.signal(signal.SIGALRM, handler)

    while True:
        print('Waiting....')
        time.sleep(2)

    Waiting....
    Waiting....
    Waiting....
    时间到了
    Waiting....
    ^CCTRL + C 无效
    Waiting....
    Waiting....
    Waiting....
    ...
----------
python3-参数中的冒号与箭头:
    冒号后面是建议传入的参数类型
    箭头后面是建议函数返回的类型
例：

def greeting(name: str) -> str:
    return 'Hello ' + name
并非强制
----------
Python通过字符串名导入模块: importlib.import_module
.. coding:: python
    def import_string(dotted_path):
    """
    Import a dotted module path and return the attribute/class designated by the
    last name in the path. Raise ImportError if the import failed.
    """
        try:
            module_path, class_name = dotted_path.rsplit('.', 1)
        except ValueError as err:
            raise ImportError("%s doesn't look like a module path" % dotted_path) from err

        module = import_module(module_path)

        try:
            return getattr(module, class_name)
        except AttributeError as err:
            raise ImportError('Module "%s" does not define a "%s" attribute/class' % (
                module_path, class_name)
            ) from err
----------
In [6]: sys.exc_info?
Docstring:
exc_info() -> (type, value, traceback)  exc_type, exc_value, exc_traceback = sys.exc_info()[:3]
----------
nonlocal关键字用来在函数或其他作用域中使用外层(非全局)变量
.. coding:: python
    def function():
        x = 100
        def incr(y):
            x = x + y
        incr(100)
    >>> UnboundLocalError: local variable 'x' referenced before assignment

    def function():
    x = 100
    def incr(y):
        nonlocal x
        x = x + y
    incr(100)
    print(x)
----------
Dict一般情况下耗时排序(从大到小)

for k,v in dict.items()  dict.items()方法的耗时要远远大于其他方法
>>
for k,v in zip(d.iterkeys(),d.itervalues())
>
for k,v in d.iteritems()
>
for i in d.keys()
>
for i in d.iterkeys()
=
for i in d
----------
Example NumPy Style Python Docstrings: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html#example-numpy
Example Google Style Python Docstrings: https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html#example-google
----------
Python3中字符串与字节之间相互转换
字符串转字节 str --> bytes
    print(str.encode(b))  # 默认 encoding="utf-8"
    print(bytes(b, encoding="utf8"))
    print(b.encode())      # 默认 encoding="utf-8"

字节转字符串 bytes --> str
    print(bytes.decode(a))   # 默认encoding="utf-8"
    print(str(a, encoding="utf-8"))
    print(a.decode())       # 默认 encoding="utf-8"
----------
catch Broken Pipe
.. coding:: python
    try:
    # do something
    except socket.error, e:
        # A socket error
    except IOError, e:
        if e.errno == errno.EPIPE:
            # EPIPE error
        else:
            # Other error
----------
islice(iterable, [start, ] stop [, step]): 创建一个迭代器，生成项的方式类似于切片返回值: iterable[start : stop : step]，将跳过前start个项，迭代在stop所指定的位置停止，step指定用于跳过项的步幅。与切片不同，负值不会用于任何start，stop和step，如果省略了start，迭代将从0开始，如果省略了step，步幅将采用1.
----------
submit gives results as soon as any thread in the ThreadPoolExecutor maxThreads=2 completes. map gives results in the order they are submitted.
----------
itertools product:
.. coding:: python
    >>> for i in product(['a','b','c'],['0','1']):print i
    ('a', '0')
    ('a', '1')
    ('b', '0')
    ('b', '1')
    ('c', '0')
    ('c', '1')
----------
httpie 发送multipart/form-data:
    http **-f** patch http://127.0.0.1:7744/device/device_model/1/ tboxFactoryNote='tfn' Authorization:"$token"
requests.patch(url+'1/', headers={'AUTHORIZATION': token}, data=data)
----------
Let’s recap what your WSGI Web server has to do to serve requests aimed at a WSGI application:

First, the server starts and loads an ‘application’ callable provided by your Web framework/application
Then, the server reads a request
Then, the server parses it
Then, it builds an ‘environ’ dictionary using the request data
Then, it calls the ‘application’ callable with the ‘environ’ dictionary and a ‘start_response’ callable as parameters and gets back a response body.
Then, the server constructs an HTTP response using the data returned by the call to the ‘application’ object and the status and response headers set by the ‘start_response’ callable.
And finally, the server transmits the HTTP response back to the client
----------
set 可变 frozenset 不可变 how to hash a dict: hash(frozenset(my_dict.items()))
----------
Python的select方法直接调用操作系统的IO接口，它监控sockets, open files, and pipes(所有带fileno()方法的文件句柄)何时变成readable和writeable, 或者通信错误，select()使得同时监控多个连接变的简单，并且这比写一个长循环来等待和监控多客户端连接要高效，因为select直接通过操作系统提供的C的网络接口进行操作，而不是通过Python的解释器。
----------
**grequests**组合了HTTP库请求和gevent，其结果就是具有很简单的API来做并发HTTP请求
.. coding:: python
    import grequests

    def run_experiment():
        urls = (url for url in urls)
        response_futures = (grequests.get(u) for u in urls)
        responses = grequests.imap(response_futures, size = 100)  # Concurrently converts a generator object of Requests to a generator of Responses
        response_size = sum(len(r.text) for r in responses)
        return response_size
----------
nonlocal声明的变量不是局部变量,也不是全局变量,而是外部嵌套函数内的变量。
----------
Python 保存 excel 里的图片文件
.. coding:: python
    import zipfile
    XLSname = "/Users/user/myfile.xlsx"
    EmbeddedFiles = zipfile.ZipFile(XLSname).namelist()
    ImageFiles = [F for F in EmbeddedFiles if F.count('.jpg') or F.count('.jpeg') ]

    for Image in ImageFiles:
        zipfile.ZipFile(XLSname).extract(Image, '/Path to save')
----------
def compute_months(self, first_date, second_date):
    year1, month1, year2, month2 = map(
        int,
        (first_date[:4], first_date[5:7], second_date[:4], second_date[5:7])
    )

    months = [
        '{:0>4}-{:0>2}'.format(year, month)
        for year in range(year1, year2 + 1)
        for month in range(month1 if year == year1 else 1, month2 + 1 if year == year2 else 13)
    ]
    months.reverse()
    return months

from datetime import date, timedelta

sdate = date(2008, 8, 15)   # start date
edate = date(2008, 9, 15)   # end date

delta = edate - sdate       # as timedelta

for i in range(delta.days + 1):
    day = sdate + timedelta(days=i)
    print(day)
----------
enum
Python has had type hinting for a while now — you knew that, right? Big companies are type hinting their code and so should you because the power of types can even make shitty languages less shitty. Before types, Python had already started moving in this direction with the enum module. It allows you to define a type as a set of predefined constants much like in other languages. Here’s an example from the documentation:
.. coding:: python
    >>> from enum import Enum
    >>> class Color(Enum):
    ...     RED = 1
    ...     GREEN = 2
    ...     BLUE = 3
    ...
    >>> print(Color.RED)
    Color.RED
    >>> print(Color.RED.name)
    RED
    >>> print(Color.RED.value)
    1
----------
aiohttp get pass params
.. coding:: python
    payload = [('key', 'value1'), ('key', 'value2')]
    async with aiohttp.get('http://httpbin.org/get',
                           params=payload) as r:
        assert r.url == 'http://httpbin.org/get?key=value2&key=value1'
----------
Convert file to base64 string on Python 3
.. coding:: python
    >>> import base64
    >>> example = b'\x01'*10
    >>> example
    b'\x01\x01\x01\x01\x01\x01\x01\x01\x01\x01'
    >>> result = base64.b64encode(example).decode('ascii')
    >>> print(repr(result))
    'AQEBAQEBAQEBAQ=='
----------
log formatter color
.. coding:: python
    import logging
    class CustomFormatter(logging.Formatter):
        """Logging Formatter to add colors and count warning / errors"""
        # **BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE = range(8)**
        # color = "\x1b[3%d;21m" % (num)
        # ;1m bold style
        grey = "\x1b[38;21m"
        yellow = "\x1b[33;21m"
        red = "\x1b[31;21m"
        bold_red = "\x1b[31;1m"
        reset = "\x1b[0m"
        format = '[%(levelname)s][logger: %(name)s][%(asctime)s][%(filename)s: %(lineno)d][%(message)s]'

        FORMATS = {
            logging.DEBUG: grey + format + reset,
            logging.INFO: grey + format + reset,
            logging.WARNING: yellow + format + reset,
            logging.ERROR: red + format + reset,
            logging.CRITICAL: bold_red + format + reset
        }

        def format(self, record):
            log_fmt = self.FORMATS.get(record.levelno)
            formatter = logging.Formatter(log_fmt)
            return formatter.format(record)
----------
In [9]: json.dumps(())
Out[9]: '[]'
----------
协程 (Coroutine) 本质上是一个函数，特点是在代码块中可以将执行权交给其他协程：
.. coding:: python
    import asyncio

    async def a():
        print('Suspending a')
        await asyncio.sleep(0)
        print('Resuming a')

    async def b():
        print('In b')

    async def main():
        await asyncio.gather(a(), b())

    if __name__ == '__main__':
        asyncio.run(main())
        # Suspending a
        # In b
        # Resuming a

1. 在协程a中，有一句 await asyncio.sleep(0)，await表示调用协程，sleep 0 并不会真的sleep因为时间为0，但是却可以把控制权交出去了。
2. asyncio.run 是 Python 3.7 新加的接口，要不然你得这么写:
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
    loop.close()
----------
How can I add attributes to a module at run time?
    setattr(sys.modules[__name__], 'attr1', 'attr1')
----------
aiohttp supports multiple types of streaming uploads, which allows you to send large files without reading them into memory.

As a simple case, simply provide a file-like object for your body:
.. coding:: python
    with open('massive-body', 'rb') as f:
       await session.post('http://httpbin.org/post', data=f)

    # Or you can use asynchronous generator:

    async def file_sender(file_name=None):
        async with aiofiles.open(file_name, 'rb') as f:
            chunk = await f.read(64*1024)
            while chunk:
                yield chunk
                chunk = await f.read(64*1024)

    # Then you can use file_sender as a data provider:

    async with session.post('http://httpbin.org/post',
                            data=file_sender(file_name='huge_file')) as resp:
        print(await resp.text())

    # Because the content attribute is a StreamReader (provides async iterator protocol), you can chain get and post requests together:

    resp = await session.get('http://python.org')
    await session.post('http://httpbin.org/post',
                       data=resp.content)
----------
In Dynamic Programming we store the solution to the problem so we do not need to recalculate it. By finding the solutions for every single sub-problem, we can tackle(应付) the original problem itself.

Memoisation is the act of storing a solution.

There are 3 main parts to divide and conquer:
    1. Divide the problem into smaller sub-problems of the same type.
    2. Conquer - solve the sub-problems recursively.
    3. Combine - Combine all the sub-problems to create a solution to the original problem.

Dynamic programming has one extra step added to step 2. This is memoisation. The purpose of dynamic programming is to not calculate the same thing twice.
.. coding:: python
    def fibonacciVal(n):
        memo[0], memo[1] = 0, 1
        for i in range(2, n+1):
            memo[i] = memo[i-1] + memo[i-2]
        return memo[n]
----------